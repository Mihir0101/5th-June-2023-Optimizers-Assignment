{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562485f1-2b3a-4e21-b8f0-a7be70165fd6",
   "metadata": {},
   "source": [
    "# **Part 1: Understanding Optimizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0daaef-a8b5-4c8b-afa5-694b9e1055e4",
   "metadata": {},
   "source": [
    "## Q1. What is the role of optimization algorithms in artificial neural networks? Why are they necessary?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18d6f27-2510-49e8-b69c-19646a9e79f2",
   "metadata": {},
   "source": [
    "* **Role of Optimizers in ANN**\n",
    "\n",
    "1. **Minimizing Loss Function** : The main objective of the optimizers is to minimize the loss by setting the best set of parameters. Optimizers minimizes the loss by iteratively adjusting values of parameters.\n",
    "\n",
    "2. **Gradient Decent** : Most of the optimizers rely on the gradient decent, which requires computation of gradients of loss function with respect to weights and bias. The gradient provides the direction and mangnitude for the best loss.\n",
    "\n",
    "3. **Parameter Updation** : Algorithm determines the size of step taken in the parameter space during each iteration, known as learning rate. Optimized size of steps helps to reach the minimum of loss effieciently.\n",
    "\n",
    "* **Why are they necessary?**\n",
    "\n",
    "1. **Training Efficiency** : Without optimization algorithms, training an ANN would be impractically slow or even impossible. These algorithms ensure efficient and systematic adjustments of parameters to speed up convergence.\n",
    "\n",
    "2. **Scalability** : Optimization algorithms enable the training of large-scale neural networks with millions of parameters, which would be otherwise unmanageable.\n",
    "\n",
    "3. **Performance** : They improve the model's ability to generalize from training data to unseen data, reducing overfitting and underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1f5775-0579-4e32-b38b-934c2c4191a2",
   "metadata": {},
   "source": [
    "## 2. Explain the concept of gradient descent and its variants. Discuss their differences and tradeoffs in terms of convergence speed and memory requirements?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a30112b-47d9-4362-844c-ed4f540f6726",
   "metadata": {},
   "source": [
    "* **Concept of Gradient Decent** : Gradient decent is used to minimize the loss function by iteratively moving towards the steepest part of gradient decent, determined by the nagitive of gradient.\n",
    "\n",
    "* **Variantes of Gradient Decent**\n",
    "\n",
    "Batch Gradient Descent :  Computes the gradient using the entire dataset.\n",
    "\n",
    "Stochastic Gradient Descent (SGD) :  Computes the gradient using only one sample at a time.\n",
    "\n",
    "Mini-Batch Gradient Descent : Computes the gradient using a small batch of samples.\n",
    "\n",
    "Gradient Descent with Momentum : Accumulates an exponentially decaying moving average of past gradients.\n",
    "\n",
    "RMSprop : Adapts the learning rate for each parameter based on a moving average of squared gradients.\n",
    "\n",
    "Adam (Adaptive Moment Estimation) : Combines the benefits of Momentum and RMSprop.\n",
    "\n",
    "* **Tradeoffs in Terms of Convergence Speed and Memory Requirements**\n",
    "\n",
    "* Convergence Speed :\n",
    "\n",
    "Batch Gradient Descent: Slow convergence per iteration but precise.\n",
    "\n",
    "SGD: Faster per iteration but noisier updates can lead to instability.\n",
    "\n",
    "Mini-Batch Gradient Descent: Strikes a balance, reducing variance while maintaining efficiency.\n",
    "\n",
    "Momentum, RMSprop, Adam: Generally faster and more stable, with Adam being one of the most popular due to its adaptive nature.\n",
    "\n",
    "* Memory Requirements :\n",
    "\n",
    "Batch Gradient Descent: High, as the entire dataset must be loaded.\n",
    "\n",
    "SGD: Low, since only one sample is processed at a time.\n",
    "\n",
    "Mini-Batch Gradient Descent: Moderate, depending on batch size.\n",
    "\n",
    "Advanced Methods: Higher than basic methods, due to additional memory needed for storing past gradients and moments (e.g., Momentum, RMSprop, Adam)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc11684-eeab-4da6-a614-4ac58471b857",
   "metadata": {},
   "source": [
    "## 3. Describe the challenges associated with traditional gradient descent optimization methods (e.g., slow convergence, local minima). How do modern optimizers address these challenges?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5080dec0-9ca6-42ee-ac02-d1f21695e697",
   "metadata": {},
   "source": [
    "* **Challenges**\n",
    "\n",
    "1. **Slow Convergence** : Traditional gradient descent methods, especially Batch Gradient Descent, can converge slowly, particularly for large datasets and deep networks.\n",
    "\n",
    "2. **Local Minima and Saddle Points** : The loss landscape is non-convex in neural network, which contains many local minima and saddle points.\n",
    "\n",
    "3. **Vanishing and Exploiding Gradients** : Gradient can become very large or very small during the backpropagation.\n",
    "\n",
    "* **How modern optimizers addresses this challenges**\n",
    "\n",
    "1. **Adaptive Learning Rates** : RMS Prop and AdaGrad adjustes the learning rate for every parameters on the basis of historical gradient. It can be help in faster and stable convergence.\n",
    "\n",
    "2. **Momentum Based Methods** : These methods accumulate a velocity vector in the direction of persistent reduction in the loss function.\n",
    "\n",
    "3. **Handling vanishing and exploding gradients** : Gradient clipping and batch normalization helps to  maintain numerical stability and enable the training of deeper networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d080a36-a8b8-4e0f-a669-7fd51b049612",
   "metadata": {},
   "source": [
    "## 4. Discuss the concepts of momentum and learning rate in the context of optimization algorithms. How do they impact convergence and model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a85ef3-1663-4c44-a94a-f6b738d84259",
   "metadata": {},
   "source": [
    "* **Momentum**\n",
    "\n",
    "**Concept** : Momentum is a technique used in optimization algorithms to accelerate convergence and smooth out oscillations by incorporating past gradient information into the current update step. It aims to build up velocity in directions with consistent gradients, allowing the optimization process to traverse plateaus and navigate valleys in the loss landscape more effectively.\n",
    "\n",
    "**Impact in Convergence and Model Performance** \n",
    "\n",
    "Accelerate Convergence : By accumulating the running average of past gradients, momentum helps to accelerate the convergence, especially in regions where the gradient consistently points in the same direction.\n",
    "\n",
    "Navigatin Plateaus and Saddle Points : Momentum aids in traversing flat region of the loss landscape, where gradients are low and progress is slow.\n",
    "\n",
    "* **Learning Rate**\n",
    "\n",
    "**Concept** : Learning rate is a crucial hyperparameter in optimization algorithem, which determines the step size for each iteration of parameter update. It controls how much the parameters are adjusted in the direction of the gradient.\n",
    "\n",
    "**Impact in Convergence and Model Performance**\n",
    "\n",
    "Convergence Speed : Can lead to a faster convergence but there is a problem of overshooting the minimum, which can cause the potential divergence.\n",
    "\n",
    "Model Performance : Optimal learning rate can strike the balance between convergence speed and stability, leading to effective trainig and efficient model performance. Also adaptive learning rate can improve convergence and generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52456a8c-edef-47d1-9a29-50f94f4e5ea3",
   "metadata": {},
   "source": [
    "## **Part 2: Optimizer Techniques**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce28a74e-80d0-496e-a599-1aae9a668525",
   "metadata": {},
   "source": [
    "## 5.Explain the concept of Stochastic gradient Descent (SGD) and its advantages compared to traditional gradient descent. Discuss its limitations and scenarios where it is most suitable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4372686e-a22a-41ea-aaff-8f45d757ce54",
   "metadata": {},
   "source": [
    "* Stochastic gradient decent is an optimizer used to minimize the loss function. It creates the gradient of loss function with respect to parameter of just single sample.\n",
    "\n",
    "* **Mathematical Formulation** : θt+1 = θt − η * ∇θJ\n",
    "\n",
    "                             where θt = Parameter | η = Learning Rate | ∇θJ = Gradient\n",
    "                             \n",
    "                             \n",
    "* **Advantages compared to Traditional Gradient Decent**\n",
    "\n",
    "Faster Convergence : SGD can converge faster than traditional gradient descent, which requires a signle sample over the dataset for each update.\n",
    "\n",
    "Computationaly Efficient : It is computationaly efficient because of using only single sample, which makes it more suitable for large datasets.\n",
    "\n",
    "Escaping local minima and saddle point : The inherent noise in the updated parameter can help them to escape the local minima and saddle point.\n",
    "\n",
    "* **Limitations of SGD**\n",
    "\n",
    "Unstable : Parameter updation can be unstable and noisy as compare to the batch gradient decent.\n",
    "\n",
    "Learning Rate : Deciding the value of learning rate is too defficult and challenging,because of too high value algorithm may diverge, and too small can make the algorithm slow.\n",
    "\n",
    "Convergence Problem : SGD may not reach the global minima all the time, especially when the loss landscape is non-convex.\n",
    "\n",
    "* **Scenario where SGD is most suitable** \n",
    "\n",
    "Large Dataset : It is highely effective for training the large datasets where it is impracticle to compute gradients over the whole datasets.\n",
    "\n",
    "Online Learning : In scenario where data arrieves from stream and model needs to be updated, SGD is ideal optimizer due to its ability to update the model with each new sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759f247c-981e-473c-b176-d31842687824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "887d46ae-d8b2-442e-90be-3a6cf1f729a0",
   "metadata": {},
   "source": [
    "## 6.Describe the concept of Adam optimizer and how it combines momentum and adaptive learning rates. Discuss its benefits and potential drawbacks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d2465f-6b7d-48a4-ba7c-927051477678",
   "metadata": {},
   "source": [
    "Adam is a optimization algorithm designed for advantages of both momentum and adaptive learning rate. It is mostly used in deep neural network because of its efficiency and performance.\n",
    "\n",
    "* **How Adam combines the Momentum and Adaptive learning rate**\n",
    "\n",
    "1. **Momentum** : \n",
    "\n",
    "Adam maintains the exponentialy decaying average of previous gradient,similar to momentum,for smoothing the updation process.\n",
    "\n",
    "Update Rule: mt = β * mt−1 + (1−β)gt\n",
    "\n",
    "2. **Adaptive Learning Rates** :\n",
    "\n",
    "Adam also keeps an exponentially decaying average of past squared gradients, which allows it to adaptively adjust the learning rate for each parameter.\n",
    "\n",
    "vt = β2 * vt − 1 + (1−β2)gt2\n",
    "\n",
    "* **Benefites**\n",
    "\n",
    "-> Adam converges faster than other convergence alorithm because of its properties like momentum and adaptive learning rate.\n",
    "\n",
    "-> The bias correction steps improves the accuracy and reliability of the optimization process, especially in the initial stage of training.\n",
    "\n",
    "-> Default hyperparameter of the Adam works well in the practice, reducing the need for extensive hyperparameter tuning.\n",
    "\n",
    "* **Drawbacks**\n",
    "\n",
    "-> Sometimes aggressive adaption of learning rate can cause the worst generalization performance.\n",
    "\n",
    "-> Adam requires additional storage to store the first and second moment average, it can be significant for large models with many parameters.\n",
    "\n",
    "-> Adam can struggle in flat region and local minima of loss landscape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6229aee6-b90c-4d7a-87a4-6ceb44963baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "082ae52a-8cf7-4095-a37e-c5284aaf1043",
   "metadata": {},
   "source": [
    "## 7.Explain the concept of RMSprop optimizer and how it addresses the challenges of adaptive learning rates. Compare it with Adam and discuss their relative strengths and weaknesses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ac6098-bb06-4d75-9cee-384231e96e55",
   "metadata": {},
   "source": [
    "RMSprop is an optimization algorithm designed for adaptively adjust the learning rate by addressing the problem of varible learning rates.\n",
    "\n",
    "It modifies the standard gradient decent by dividing the gradient by the running  average of recent mangnitude, which helps in vanishing and exploiding gradient.\n",
    "\n",
    "* **How RMSprop Addresses Challenges of Adaptive Learning Rates**\n",
    "\n",
    "RMSprop adjusts the learning rate for each parameter individually based on the magnitude of recent gradients. This helps to ensure that each parameter is updated appropriately, even if the gradients vary in scale.\n",
    "\n",
    "By normalizing the gradients using the running average of their magnitudes, RMSprop prevents the gradients from becoming too large or too small.\n",
    "\n",
    "* **Comparision with Adam**\n",
    "\n",
    "Adam builds on the ideas of RMSprop by incorporating momentum and bias correction mechanisms.\n",
    "\n",
    "* **Relative strengths and weaknesses of RMSprop and Adam**\n",
    "\n",
    "* Strengths of RMSprop : \n",
    "\n",
    "RMSprop have fewer parameters to tune as compare to adam, which makes it simpler.\n",
    "\n",
    "It requires less memory than adam.\n",
    "\n",
    "* Strengths of Adam :\n",
    "\n",
    "Adam includes momentum which smooths the updation process.\n",
    "\n",
    "Adam corrects bias in first and second moment estimation, that improves accuracy in optimization.\n",
    "\n",
    "Adam's default hyperparameters works well in most of the types of problems.\n",
    "\n",
    "* Weaknesses of RMSprop :\n",
    "\n",
    "RMSprop doesn't includes the momentum term.\n",
    "\n",
    "It doesn't corrects the bias in the initial stages of the training.\n",
    "\n",
    "* Weaknesses of Adam :\n",
    "\n",
    "Adam requires more memory than RMSprop.\n",
    "\n",
    "Due to the aggressive adaption of learning rate, Adam can cause the worst genrelization of optimization than simpler optimizers like Stochastic Gradient Decent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ca4c30-efe9-4be3-bf52-ce09df68e297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5830b9f7-ab30-449b-9af7-793d5e22f1f0",
   "metadata": {},
   "source": [
    "## **Part 3: Applying Optimizers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277b4647-d79d-4649-bbb0-41fbdebde275",
   "metadata": {},
   "source": [
    "## 8. Implement Sgd, Adam, and RMSprop optimizers in a deep learning model using a framework of your choice. Train the model on a suitable dataset and compare their impact on model convergence and performancen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54da9bb9-e201-40c2-9232-262a4fc47f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting tensorboard<2.18,>=2.17\n",
      "  Downloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting keras>=3.2.0\n",
      "  Downloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (22.0)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.21.11)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.65.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=24.3.25\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=3.10.0\n",
      "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (65.5.1)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1\n",
      "  Downloading ml_dtypes-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.28.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Collecting rich\n",
      "  Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting namex\n",
      "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting optree\n",
      "  Downloading optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (347 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.7/347.7 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.13)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.1)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (2.13.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, opt-einsum, ml-dtypes, mdurl, markdown, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, optree, markdown-it-py, rich, keras, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.7.0\n",
      "    Uninstalling h5py-3.7.0:\n",
      "      Successfully uninstalled h5py-3.7.0\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.65.1 h5py-3.11.0 keras-3.4.1 libclang-18.1.1 markdown-3.6 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.0 namex-0.0.8 opt-einsum-3.3.0 optree-0.12.1 rich-13.7.1 tensorboard-2.17.0 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.4.0 typing-extensions-4.12.2 werkzeug-3.0.3 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d145a57-1fe4-4ff6-8b1e-7840304889b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c8b7061-ccac-4355-af73-9bc267b4b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f926985-726a-46ca-a3d1-551d6f21758f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84e692be-7b2b-4937-9dac-6712cc442fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid,x_train = x_train[:7000]/255 , x_train[7000:]\n",
    "x_test = x_test / 255\n",
    "y_valid,y_train = y_train[:7000] , y_train[7000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c060b7ae-b6ae-41d9-bc69-996c277fcf25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efb93b35ed0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_valid[6999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71c2ad50-d13d-41c4-bc6c-8267baa690db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bb4aa3f-0ea9-4c48-b3ae-79acee427e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │         \u001b[38;5;34m1,200\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │           \u001b[38;5;34m400\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">268,210</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m268,210\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">267,410</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m267,410\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> (3.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m800\u001b[0m (3.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LAYERS = [\n",
    "         tf.keras.layers.Flatten(input_shape=[28,28]),\n",
    "         tf.keras.layers.Dense(300,activation='relu',kernel_regularizer = regularizers.l2(1e-4)),\n",
    "         tf.keras.layers.Dropout(0.3),\n",
    "         tf.keras.layers.BatchNormalization(),\n",
    "         tf.keras.layers.Dense(100,activation='relu',kernel_regularizer=regularizers.l2(1e-4)),\n",
    "         tf.keras.layers.BatchNormalization(),\n",
    "         tf.keras.layers.Dense(10,activation='softmax',kernel_regularizer=regularizers.l2(1e-4))\n",
    "         ]\n",
    "\n",
    "model = tf.keras.models.Sequential(LAYERS)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e0679f-4b46-4472-bcad-698aabdbd8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a08d425-a5c4-48eb-963c-aea90d8e97d3",
   "metadata": {},
   "source": [
    "**Optimizer = SGD | Accuracy = 0.9680**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9acab3bb-938b-4b1e-a598-97f45f289cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS = 'sparse_categorical_crossentropy'\n",
    "OPTIMIZER = tf.keras.optimizers.SGD(learning_rate=0.01,momentum=0.9)\n",
    "METRICS = ['accuracy']\n",
    "\n",
    "model.compile(loss=LOSS,optimizer=OPTIMIZER,metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aca2f2-d078-4901-a304-73d2c47c141e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d0d0c28-30c9-4f14-9c37-cc3a0b8f3006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8529 - loss: 0.5911 - val_accuracy: 0.0871 - val_loss: 3.2350\n",
      "Epoch 2/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9360 - loss: 0.4960 - val_accuracy: 0.0871 - val_loss: 3.3637\n",
      "Epoch 3/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9480 - loss: 0.5481 - val_accuracy: 0.1013 - val_loss: 3.5733\n",
      "Epoch 4/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9526 - loss: 0.7415 - val_accuracy: 0.0871 - val_loss: 4.3355\n",
      "Epoch 5/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9561 - loss: 0.7056 - val_accuracy: 0.0871 - val_loss: 4.4114\n",
      "Epoch 6/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9594 - loss: 0.6919 - val_accuracy: 0.0871 - val_loss: 3.5633\n",
      "Epoch 7/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9616 - loss: 0.6714 - val_accuracy: 0.0871 - val_loss: 3.7718\n",
      "Epoch 8/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9627 - loss: 0.9203 - val_accuracy: 0.0871 - val_loss: 3.9872\n",
      "Epoch 9/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9607 - loss: 0.8811 - val_accuracy: 0.0871 - val_loss: 3.7848\n",
      "Epoch 10/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9628 - loss: 0.8599 - val_accuracy: 0.0871 - val_loss: 4.4916\n",
      "Epoch 11/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9652 - loss: 0.8114 - val_accuracy: 0.0871 - val_loss: 4.6456\n",
      "Epoch 12/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9657 - loss: 0.7699 - val_accuracy: 0.0871 - val_loss: 5.2940\n",
      "Epoch 13/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9668 - loss: 0.7342 - val_accuracy: 0.0871 - val_loss: 4.7815\n",
      "Epoch 14/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9661 - loss: 0.7010 - val_accuracy: 0.0871 - val_loss: 4.4408\n",
      "Epoch 15/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9680 - loss: 0.6628 - val_accuracy: 0.0871 - val_loss: 4.6053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7efb3878b730>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_valid,y_valid),epochs=15,batch_size=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee38ee19-d8f1-47dd-acd5-c3adf1bf7f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06316142-c0ca-419f-bb90-09a8437fb3da",
   "metadata": {},
   "source": [
    "**Optimizer = Adam | Accuracy = 0.9692**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af20fa7f-e03d-4120-b423-ff2371b4ac3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9605 - loss: 0.5270 - val_accuracy: 0.0871 - val_loss: 4.2234\n",
      "Epoch 2/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9632 - loss: 0.2779 - val_accuracy: 0.0993 - val_loss: 3.1031\n",
      "Epoch 3/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9643 - loss: 0.2088 - val_accuracy: 0.0871 - val_loss: 2.8811\n",
      "Epoch 4/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9664 - loss: 0.1811 - val_accuracy: 0.0871 - val_loss: 3.3959\n",
      "Epoch 5/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9662 - loss: 0.1790 - val_accuracy: 0.0871 - val_loss: 3.1175\n",
      "Epoch 6/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9671 - loss: 0.1722 - val_accuracy: 0.0871 - val_loss: 3.2512\n",
      "Epoch 7/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9684 - loss: 0.1687 - val_accuracy: 0.0871 - val_loss: 3.3218\n",
      "Epoch 8/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9680 - loss: 0.1713 - val_accuracy: 0.0871 - val_loss: 3.4535\n",
      "Epoch 9/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9670 - loss: 0.1737 - val_accuracy: 0.0929 - val_loss: 3.1568\n",
      "Epoch 10/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9671 - loss: 0.1749 - val_accuracy: 0.0871 - val_loss: 3.8176\n",
      "Epoch 11/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9680 - loss: 0.1695 - val_accuracy: 0.0929 - val_loss: 3.3983\n",
      "Epoch 12/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9700 - loss: 0.1626 - val_accuracy: 0.0930 - val_loss: 3.4239\n",
      "Epoch 13/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9689 - loss: 0.1699 - val_accuracy: 0.0929 - val_loss: 4.0632\n",
      "Epoch 14/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9694 - loss: 0.1718 - val_accuracy: 0.0929 - val_loss: 3.1835\n",
      "Epoch 15/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9692 - loss: 0.1684 - val_accuracy: 0.0929 - val_loss: 3.4696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7efad87ced40>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_adam = tf.keras.models.Sequential(LAYERS)\n",
    "model_adam.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model_adam.fit(x_train,y_train,validation_data=(x_valid,y_valid),epochs=15,batch_size=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1e59d-07c7-41e4-944b-af109947ba8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "924ae9d5-0af6-4433-a8c4-c147be6df34d",
   "metadata": {},
   "source": [
    "**Optimizer = RMSprop | Accuracy = accuracy: 0.9678**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1edfbf9-27a1-42e8-abf2-e12348f80275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9721 - loss: 0.1523 - val_accuracy: 0.0929 - val_loss: 3.0777\n",
      "Epoch 2/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9726 - loss: 0.1422 - val_accuracy: 0.0871 - val_loss: 2.9731\n",
      "Epoch 3/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9712 - loss: 0.1433 - val_accuracy: 0.0993 - val_loss: 2.6929\n",
      "Epoch 4/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9684 - loss: 0.1480 - val_accuracy: 0.0993 - val_loss: 2.6735\n",
      "Epoch 5/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9695 - loss: 0.1450 - val_accuracy: 0.0929 - val_loss: 2.7324\n",
      "Epoch 6/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9671 - loss: 0.1464 - val_accuracy: 0.0929 - val_loss: 2.5930\n",
      "Epoch 7/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9691 - loss: 0.1437 - val_accuracy: 0.0929 - val_loss: 2.6102\n",
      "Epoch 8/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9681 - loss: 0.1491 - val_accuracy: 0.0929 - val_loss: 2.6616\n",
      "Epoch 9/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9678 - loss: 0.1470 - val_accuracy: 0.0871 - val_loss: 2.5814\n",
      "Epoch 10/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9664 - loss: 0.1489 - val_accuracy: 0.0871 - val_loss: 2.5365\n",
      "Epoch 11/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9672 - loss: 0.1472 - val_accuracy: 0.1836 - val_loss: 2.4848\n",
      "Epoch 12/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9679 - loss: 0.1481 - val_accuracy: 0.1067 - val_loss: 2.4346\n",
      "Epoch 13/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9678 - loss: 0.1485 - val_accuracy: 0.1013 - val_loss: 2.5131\n",
      "Epoch 14/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9680 - loss: 0.1466 - val_accuracy: 0.0929 - val_loss: 2.5052\n",
      "Epoch 15/15\n",
      "\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9678 - loss: 0.1475 - val_accuracy: 0.1013 - val_loss: 2.5502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7efaf817e0b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rms = tf.keras.models.Sequential(LAYERS)\n",
    "model_rms.compile(loss='sparse_categorical_crossentropy',optimizer=tf.keras.optimizers.RMSprop(),metrics=['accuracy'])\n",
    "model_rms.fit(x_train,y_train,validation_data=(x_valid,y_valid),epochs=15,batch_size=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8781193a-7464-4585-90b4-c355a2f2be22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb693390-b672-43fe-be3a-2ef7d8aa2756",
   "metadata": {},
   "source": [
    "## 9. Discuss the considerations and tradeoffs when choosing the appropriate optimizer for a given neural network architecture and task. Consider factors such as convergence speed, stability, and generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca857f7-5cad-47ef-a407-dee39144e69d",
   "metadata": {},
   "source": [
    "**Considerations**\n",
    "\n",
    "1. Convergence Speed\n",
    "\n",
    "* SGD : Often slower in convergence due to high variance in parameter updates.\n",
    "\n",
    "* RMSprop and Adam : Typically achieve faster convergence due to adaptive learning rates and efficient handling of gradients.\n",
    "\n",
    "2. Stability\n",
    "\n",
    "* SGD: Can be unstable, especially with a high learning rate.\n",
    "\n",
    "* RMSprop and Adam : Generally more stable due to adaptive learning rates, but can be sensitive to hyperparameters.\n",
    "\n",
    "3. Generalization Performance \n",
    "\n",
    "* SGD : Often leads to better generalization, especially when combined with learning rate schedules.\n",
    "\n",
    "* RMSpro and Adam : May lead to overfitting and poorer generalization in some cases. Techniques like learning rate decay can help mitigate this.\n",
    "\n",
    "**Tradeoffs**\n",
    "\n",
    "* SGD\n",
    "\n",
    "Pros: Simplicity, low memory usage, often good generalization.\n",
    "\n",
    "Cons: Slower convergence, requires careful learning rate tuning, can be unstable.\n",
    "\n",
    "* RMSprop and Adam\n",
    "\n",
    "Pros: Faster convergence, adaptive learning rates, robust performance on complex tasks.\n",
    "\n",
    "Cons: Higher memory and computational requirements, potential overfitting, sensitive to hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9410d73-daae-47c2-ad10-d1b6950778ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
